!pip install transformers>=4.40.1 accelerate>=0.27.2
#installing necessary transfomers so that the Transformers, language models and necesarry tokenizersa can be imported

from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained(
    "microsoft/Phi-3-mini-4k-instruct",
    device_map = 'cuda',
    torch_dtype = 'auto',
    trust_remote_code = 'False'
)

tokenizer = AutoTokenizer.from_pretrained("microsoft/Phi-3-mini-4k-instruct")

